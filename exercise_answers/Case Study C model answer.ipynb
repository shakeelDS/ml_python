{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example answer\n",
    "\n",
    "The code below is an example answer which shows that you can streamline some of your processing using ColumnTransform and change the order of some steps in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path\n",
    "student_performance_filepath = '../data/student_performance.csv'\n",
    "\n",
    "# Import data into a data frame.\n",
    "raw_data = pd.read_csv(filepath_or_buffer=student_performance_filepath, delimiter=\",\")\n",
    "\n",
    "column_names = list(raw_data.columns)\n",
    "print(column_names)\n",
    "raw_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "\n",
    "Before we fill in missing values in our data we should understand the distributions of the attributes with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(raw_data['lunch']).plot.bar()\n",
    "\n",
    "# converting to 0 and 1 False and True respectively \n",
    "lunch_map = {\n",
    "    False: 0,\n",
    "    True: 1\n",
    "}\n",
    "\n",
    "raw_data[\"lunch\"] = raw_data[\"lunch\"].replace(lunch_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lunch data is majority class \"False\", we can either try to impute based on the other feature values, or by replacing with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(raw_data['preparation_course']).plot.bar();\n",
    "\n",
    "# converting to 0 and 1 none and completed respectively \n",
    "preparation_map = {\n",
    "    \"none\": 0,\n",
    "    \"completed\": 1\n",
    "}\n",
    "\n",
    "raw_data[\"preparation_course\"] = raw_data[\"preparation_course\"].replace(preparation_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lunch data is majority class \"none\", we can either try to impute based on the other feature values, or by replacing with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"math_score\"].plot.density();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the \"math_score\" attribute is quite symetrically distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Data\n",
    "\n",
    "Some of our data is not yet in the appropriate format to be passed to a model, we will need to encode it. The \"gender\" feature is binary so can either be one hot encoded, label encoded or mapped to produce the same effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_map = {\n",
    "    \"female\": 0,\n",
    "    \"male\": 1\n",
    "}\n",
    "\n",
    "raw_data[\"gender\"] = raw_data[\"gender\"].replace(gender_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"parental_education\" feature is ordinal as each level of education follows on from the next. We therefore have the decision to make over whether to one hot encode it (assume the features are independent) or to set the values to integers (maintain the order, but artificially create a distance between values). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to map the values of each category to an order so we don't lose structural information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data[\"parent_education\"].unique())\n",
    "\n",
    "parent_education_map = {\n",
    "    \"some high school\": 0,\n",
    "    \"high school\": 1,\n",
    "    \"some college\": 2,\n",
    "    \"associate's degree\": 3,\n",
    "    \"bachelor's degree\": 4,\n",
    "    \"master's degree\": 5,\n",
    "}\n",
    "\n",
    "raw_data[\"parent_education\"] = raw_data[\"parent_education\"].replace(parent_education_map)\n",
    "\n",
    "# Making a copy for use later as dataframe.\n",
    "encoded_data_frame = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "We will now scale the data in appropriate manners. The binary data doesn't need to be scaled, and we have not actually one hot encoded any of the data. We are going to MinMaxScale the ordinal data and as the \"math_score\" data is quite normally distributed we will use the StandardScaler on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_scale_data_transform = ColumnTransformer(\n",
    "    [\n",
    "    ('KNN impute lunch', KNNImputer(missing_values=np.nan, n_neighbors=1), [\"lunch\"]),\n",
    "    ('KNN impute preparation_course', KNNImputer(missing_values=np.nan, n_neighbors=1), [\"preparation_course\"]),\n",
    "    ('MinMax scale', MinMaxScaler(), [\"parent_education\"]),\n",
    "    ('StandardScaler', StandardScaler(), [\"math_score\"])\n",
    "    ], remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "# This creates a separated array of the features cleaned and scaled.\n",
    "clean_data = clean_scale_data_transform.fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how our features are correlated with the target to determine if we should remove any. We are going to use the original pre-transformed data for ease of visualisation, why could this give a misleading result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the correlation matrix with pandas.\n",
    "correlation_matrix = encoded_data_frame.corr()\n",
    "\n",
    "# Show the matrix as a heatmap, matplotlib can also be used instead.\n",
    "correlation_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the features are quite significantly correlated with the \"writing_score\" attribute, and therefore have some information to pass to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to split our X and y data in order to produce a training test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = clean_data[:,-1]\n",
    "X = np.delete(clean_data, -1, axis=1)\n",
    "\n",
    "print(\"Shape of target: \", y.shape)\n",
    "print(\"Shape of features: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data set into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to choose the Lasso regression model here, as it performs generally as well as linear regression but may be able to out perform it when we tune for alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Train model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Get the MAE score from the test and prediction data.\n",
    "MSE_value = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(MSE_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a value for the MSE, but how do we know that it is good? We can try a range of other hyperparameters and check what values they produce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the documentation for the Lasso model [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) we can see that along with alpha, there are other hyperparameters which may impact the performance of our model.\n",
    "\n",
    "We are going to search through the parameters:\n",
    "* alpha\n",
    "* max_iter (the maximum numbers of iterations the algorithm goes through)\n",
    "* tol (the tolerance of the stopping condition)\n",
    "\n",
    "I am going to use the randomised search method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The range of our potential parameter values is large, therefore we sample from a \n",
    "# log uniform distribution.\n",
    "param_dist = {'alpha': loguniform(0.1, 1e4),\n",
    "              'max_iter': loguniform(100, 1e8),\n",
    "              'tol': loguniform(1e-7, 1e-1)}\n",
    "\n",
    "# Create a new model\n",
    "lasso_model_with_search = Lasso()\n",
    "\n",
    "# Create a searcher, we can define how many iterations of searching we\n",
    "# want with n_iter\n",
    "random_searcher = RandomizedSearchCV(lasso_model_with_search, \n",
    "                             param_dist, \n",
    "                             random_state=123, \n",
    "                             n_iter=2000,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "search = random_searcher.fit(X, y)\n",
    "print(\"The best parameters are:\\n\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = search.best_estimator_\n",
    "\n",
    "# Train model\n",
    "best_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred = best_lasso.predict(X_test)\n",
    "\n",
    "# Get the MAE score from the test and prediction data.\n",
    "MSE_value = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(MSE_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have significantly improved our MSE value, making our model better. We were able to use high numbers of \"n_iter\" for the searching of optimal parameters as our model is quite computationally cheap, should we have more expensive ones we may need to search more carefully with a smaller range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
