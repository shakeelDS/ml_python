{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relavent libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bikes_filepath = '../data/bikes.csv'\n",
    "\n",
    "original_data = pd.read_csv(filepath_or_buffer=bikes_filepath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Using two methods to fill in missing data as the first does not guarentee to fill all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data with linear interpolation\n",
    "clean_data = original_data.interpolate(method='linear')\n",
    "\n",
    "# Fill remaining missing data with backfilling\n",
    "clean_data = clean_data.fillna(method=\"bfill\")\n",
    "\n",
    "clean_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct data types of the examples are:\n",
    "* Ordinal\n",
    "* Numerical\n",
    "* Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create new data frame with just the weather_code attribute.\n",
    "weather_data = pd.DataFrame(clean_data[\"weather_code\"], columns=[\"weather_code\"])\n",
    "\n",
    "# Initialise the encoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit_transform the categorical data. It needs to be in an array to be transformed.\n",
    "weather_encoded_array = one_hot_encoder.fit_transform(weather_data[[\"weather_code\"]]).toarray()\n",
    "\n",
    "# Fetch the feature names for use in the column headers.\n",
    "column_names = one_hot_encoder.get_feature_names(['weather_code'])\n",
    "\n",
    "# Create a new data frame with the weather encoded data array.\n",
    "weather_encoded_data = pd.DataFrame(data=weather_encoded_array, columns=column_names)\n",
    "\n",
    "# Use the original names of the categories.\n",
    "weather_encoded_data[\"original_weather\"] = clean_data[\"weather_code\"]\n",
    "\n",
    "weather_encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **`pandas`** function **`.select_dtypes(include='number')`** to return only columns of a certain data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialise scaler\n",
    "rb_scaler = RobustScaler()\n",
    "\n",
    "# Select only numerical data and remove the target variable.\n",
    "numerical_data = clean_data.select_dtypes(include='number').drop(columns=[\"count\"])\n",
    "\n",
    "# Scale the features, produces an array.\n",
    "scaled_features_array = rb_scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Put the scaled array into a data frame. \n",
    "scaled_data = pd.DataFrame(scaled_features_array, columns=numerical_data.columns)\n",
    "\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Attach the count attribute to the data frame.\n",
    "# This needs to be done so we can find the correlation between the features and count.\n",
    "weather_encoded_data[\"count\"] = clean_data[\"count\"]\n",
    "\n",
    "# Generate the correlation coefficients using the pandas method.\n",
    "correlation_matrix = weather_encoded_data.corr()\n",
    "\n",
    "# Plot the correlation matrix.\n",
    "correlation_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Set the number of attributes\n",
    "K = 4\n",
    "\n",
    "# Remove the target and pre-encoded attributes as they are not features.\n",
    "weather_encoded_data = weather_encoded_data.drop(columns=[\"count\", \"original_weather\"])\n",
    "\n",
    "# Initialise the selector.\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_regression, k=K)\n",
    "\n",
    "# Fit the selector to the encoded weather data.\n",
    "mutual_info_selector.fit(X=weather_encoded_data, y=clean_data[\"count\"])\n",
    "\n",
    "# Find the chosen attributes with True/False values.\n",
    "columns_selected = mutual_info_selector.get_support()\n",
    "\n",
    "# Select the most important columns from the original frame.\n",
    "selected_cols = weather_encoded_data.columns[columns_selected]\n",
    "print(\"Top {} Columns are:\\n\\n\\t\".format(K), selected_cols)\n",
    "\n",
    "# Create a data frame of just the most important features.\n",
    "best_four_data = weather_encoded_data[selected_cols]\n",
    "print(columns_selected)\n",
    "best_four_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
