{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2017/03/data-science-campus-logo-new.svg\"\n",
    "             alt=\"ONS Data Science Campus Logo\"\n",
    "             width = \"240\"\n",
    "             style=\"margin: 0px 60px\"\n",
    "             />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Tuning the Selected Model\n",
    "\n",
    "Purpose of script: tune logreg on titanic_engineered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cached data from titanic_EDA.py\n",
    "titanic_engineered = pd.read_pickle('../../cache/titanic_engineered.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define processing functions\n",
    "def preprocess_target(df) :\n",
    "    # Create arrays for the features and the target variable\n",
    "    target = df['Survived'].values\n",
    "    return(target)\n",
    "\n",
    "def preprocess_features(df) :\n",
    "    #extract features series\n",
    "    features = df.drop('Survived', axis=1)\n",
    "    #remove features that cannot be converted to float: name, ticket & cabin\n",
    "    features = features.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    # dummy encoding of any remaining categorical data\n",
    "    features = pd.get_dummies(features, drop_first=True)\n",
    "    # ensure np.nan used to replace missing values\n",
    "    features.replace('nan', np.nan, inplace=True)\n",
    "    return features\n",
    "toggle_code(title='answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess target from titanic_train\n",
    "target = preprocess_target(titanic_engineered)\n",
    "#preprocess features from titanic_train\n",
    "features = preprocess_features(titanic_engineered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the necessary test and train sets using a test size of 25 % and a random state of 36\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=36)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute median for NaNs in age column\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# instantiate classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# create a list called steps, each step should be a tuple\n",
    "# required steps are 'imputation', 'scaler', 'logistic_regression'\n",
    "steps = [('imputation', imp),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('logistic_regression', logreg)]\n",
    "\n",
    "# establish pipeline\n",
    "pipeline = Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you fit the model?\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you predict the labels of the test set?\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.7934131736526946 in non-engineered df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up from 0.8116591928251121 in non engineered df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is 10% lower in the survived category. High precision == low FP \n",
    "rate. This model performs 10 % better in relation to false positives \n",
    "(assigning survived when in fact died) when class assigned is 0 than 1.\n",
    "\n",
    "Recall (false negative rate - assigning died but in truth survived) is largely\n",
    "comparable across both classes. \n",
    "\n",
    "The harmmonic mean of precision and recall - f1 - has a 6 percent increase \n",
    "when assigning 0 as survived. \n",
    "\n",
    "This has resulted in 133 rows (versus 90 rows in survived) of the true\n",
    "response sampled faling within the 0 (died) category.\n",
    "\n",
    "Overall, it appears that this model is considerably better at predicting when\n",
    "people died rather than survived.  \n",
    "\n",
    "After comparison of the two datasets and logreg vs knn, this model dataset\n",
    "combination yields the highest performance metrics across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameter space\n",
    "parameters = [\n",
    "    {'logistic_regression__C':np.logspace(-1,1,20),\n",
    "    'logistic_regression__penalty':['l2'],\n",
    "    'logistic_regression__solver': ['lbfgs'],\n",
    "    'logistic_regression__max_iter' : [50, 100, 150, 200]\n",
    "    }\n",
    "              ]\n",
    "\n",
    "# instantiate the gridsearch object with 5 fold cross validation \n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the cross validation model to the training data\n",
    "cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels of test set\n",
    "y_pred = cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned model parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
