{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2017/03/data-science-campus-logo-new.svg\"\n",
    "             alt=\"ONS Data Science Campus Logo\"\n",
    "             width = \"240\"\n",
    "             style=\"margin: 0px 60px\"\n",
    "             />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Source or Engineered Data?\n",
    "\n",
    "Purpose of script: compare logreg vs knn on titanic_engineered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cached data from titanic_EDA.ipynb\n",
    "titanic_engineered = pd.read_pickle('../../cache/titanic_engineered.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing functions\n",
    "def preprocess_target(df) :\n",
    "    # Create arrays for the features and the target variable\n",
    "    target = df['Survived'].values\n",
    "    # ensure the required object is returned\n",
    "    return(target)\n",
    "\n",
    "def preprocess_features(df) :\n",
    "    #extract features series\n",
    "    features = df.drop('Survived', axis=1)\n",
    "    #remove features that cannot be converted to float: name, ticket & cabin\n",
    "    features = features.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    # dummy encoding of any remaining categorical data\n",
    "    features = pd.get_dummies(features, drop_first=True)\n",
    "    # ensure np.nan used to replace missing values\n",
    "    features.replace('nan', np.nan, inplace=True)\n",
    "    # ensure the required object is returned\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess target from titanic_train\n",
    "target = preprocess_target(titanic_engineered)\n",
    "#preprocess features from titanic_train\n",
    "features = preprocess_features(titanic_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 3.2 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set of 25 % as in previous models\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 3.3 Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute median for NaNs in age column\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# instantiate classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "steps = [('imputation', imp),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('logistic_regression', logreg)]\n",
    "\n",
    "# establish pipeline\n",
    "pipeline = Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.7934131736526946 in non-engineered df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up from 0.8116591928251121 in non engineered df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a report of performance metrics, passing the true test labels and predicted labels as arguments in that order\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is 10% lower in the survived category. High precision == low FP \n",
    "rate. This model performs 10 % better in relation to false positives \n",
    "(assigning survived when in fact died) when class assigned is 0 than 1.\n",
    "\n",
    "Recall (false negative rate - assigning died but in truth survived) is largely\n",
    "comparable across both classes. \n",
    "\n",
    "The harmmonic mean of precision and recall - f1 - has a 6 percent increase \n",
    "when assigning 0 as survived. \n",
    "\n",
    "This has resulted in 133 rows (versus 90 rows in survived) of the true\n",
    "response sampled faling within the 0 (died) category.\n",
    "\n",
    "Overall, it appears that this model is considerably better at predicting when\n",
    "people died rather than survived.  \n",
    "\n",
    "After comparison of the two datasets and logreg vs knn, this model dataset\n",
    "combination yields the highest performance metrics across the board.\n",
    "\n",
    "Ultimately, this is the model selected to take forward. Compared to other \n",
    "models this had highest accuracy and F1 scores. I believe this to be more\n",
    "important due to minor class imbalance and no preference on TP or FN rate. \n",
    "Next closest model was KNN on titanic_train, had equivalent accuracy and \n",
    "F1 scores but both precision and recall were more balanced in this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operator Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of a sample being in a particular class\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve (titanic_train)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the ROC curve has changed shape from the same plotted on titanic_train, particularly in the p=0.8 to p=0.6 range. Effect on auc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.8787802840434419. The AUC here has declined by 0.004 from the untrained model, indicating a slight decline in untuned model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy up\n",
    "del fpr, logreg, pipeline, steps, thresholds, tpr, y_pred, y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## KNearestNeighbours\n",
    "\n",
    "## Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('imputation', imp),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('knn', KNeighborsClassifier(5))]\n",
    "\n",
    "# establish pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the pipeline model\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.8697604790419161 in non engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up from 0.7937219730941704 in non engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive rate similar to logreg but true negative count is higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is still lower within the survived category, however the difference\n",
    "has now reduced from 10 % to 7 % lower than the logreg model. Crucially though,\n",
    "precision is down overall, with a macro average reduction of 2 %. \n",
    "\n",
    "Recall (false negative rate - assigning died but in truth survived) within the\n",
    "survived predicted group has decreased by 4 % than in logreg.\n",
    "\n",
    "The KNN model appears to perform poorly against the logreg model in terms of\n",
    "both precision and recall. harmonic mean of these - f1 is similarly reduced\n",
    "by 1 to 2% depending on favouring macro vs weighted average. \n",
    "\n",
    "support output has been unaffected. \n",
    "\n",
    "interesting, in terms of precision and recall, KNN appears to be outperformed\n",
    "by logreg. This is also true of accuracy in training. But \n",
    "(and possibly an important point) accuracy against the test set improved over\n",
    "logreg by ~2.7 %. This could indicate a degree of overfitting within the \n",
    "untuned logreg model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision above to select titanic_engineered to take forward with logreg model.\n",
    "However, one question still persists, what affect (if any) did imputation of \n",
    "age with median make to performance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operator Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of a sample being in a particular class\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve (titanic_train)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To my eye this looks identical to the knn on titanic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can you quantify the area under the roc curve?\n",
    "roc_auc_score(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.8715538847117794. This is a marked decline in model performance. It is possible that the engineered features are merely duplicating relationships already encoded within the titanic_train data. KNN would then I assume be affected by duplication of this data. AUC has declined by ~ 0.01, an order of magnitude larger than in previous AUC comparisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "del fpr, pipeline, steps, thresholds, tpr, y_pred, y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## titanic_no_age\n",
    "\n",
    "Rather than imputing median values for the age column, would it be advantageous to simply remove the age column altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you remove the Age column?\n",
    "titanic_no_age = titanic_engineered.drop('Age', axis=1)\n",
    "titanic_no_age.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess target from titanic_train\n",
    "target = preprocess_target(titanic_no_age)\n",
    "#preprocess features from titanic_train\n",
    "features = preprocess_features(titanic_no_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute median for NaNs in age column\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# instantiate classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "steps = [('imputation', imp),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('logistic_regression', logreg)]\n",
    "\n",
    "# establish pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.7919161676646707 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 0.8340807174887892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a confusion matrix, passing the true test labels and predicted labels as arguments in that order\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tp the same but tn reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall, f1 and accuracy are down across the board in each class and\n",
    "on average. deletion of the age column is clearly not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operator Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of a sample being in a particular class\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve (titanic_train)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To my eye this looks largely similar to the logreg on titanic_engineered ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up from 0.8740183792815372. AUC has improved by ~0.01, a marked improvement over logreg on titanic_engineered. How can this be when the classification report showed performance down across the board?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
